{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sentence    Wow... Loved this place.\nlabel                              1\ncompany                         yelp\nName: 0, dtype: object\n"
    }
   ],
   "source": [
    "dict_filepath= { 'yelp': 'sentiment_sentences/yelp_labelled.txt',\n",
    "'amazon': 'sentiment_sentences/amazon_cells_labelled.txt',\n",
    "'imdb': 'sentiment_sentences/imdb_labelled.txt'\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for company, filepath in dict_filepath.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['company'] = company\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            sentence  label company\n0                           Wow... Loved this place.      1    yelp\n1                                 Crust is not good.      0    yelp\n2          Not tasty and the texture was just nasty.      0    yelp\n3  Stopped by during the late May bank holiday of...      1    yelp\n4  The selection on the menu was great and so wer...      1    yelp",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>company</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wow... Loved this place.</td>\n      <td>1</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Crust is not good.</td>\n      <td>0</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Not tasty and the texture was just nasty.</td>\n      <td>0</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stopped by during the late May bank holiday of...</td>\n      <td>1</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The selection on the menu was great and so wer...</td>\n      <td>1</td>\n      <td>yelp</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2748 entries, 0 to 747\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   sentence  2748 non-null   object\n 1   label     2748 non-null   int64 \n 2   company   2748 non-null   object\ndtypes: int64(1), object(2)\nmemory usage: 85.9+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How We Would Predict The Data\n",
    "\n",
    "\n",
    "'''\n",
    "A collection of text is called a CORPUS\n",
    "\n",
    " In a feature vector, each dimension can be a numeric or categorical feature, like for example the height of a building, the price of a stock, or, in our case, the count of a word in a vocabulary. These feature vectors are a crucial piece in data science and machine learning, as the model you want to train depends on them.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'John': 0, 'likes': 5, 'ice': 4, 'cream': 2, 'hates': 3, 'chocolate': 1}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sentences = ['John likes ice cream', 'John hates chocolate.']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1, 0, 1, 0, 1, 1],\n       [1, 1, 0, 1, 0, 0]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "vectorizer.transform(sentences).toarray()\n",
    "\n",
    "# Resulting feature vectors for each sentence based on previpus vocabulary\n",
    "'''\n",
    "For example, if you take a look at the first item, you can see that both vectors have a 1 there. This means that both sentences have one occurrence of John, which is in the first place in the vocabulary.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is when a model is trained too well on the training data. You want to avoid overfitting, as this would mean that the model mostly just memorized the training data. This would account for a large accuracy with the training data but a low accuracy in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The .values returns a NumPy array instead of a Pandas Series object which is in this context easier to work with:\n",
    "\n",
    "'''\n",
    "   'the presentation of the food was awful.',\n",
    "       \"I can't tell you how disappointed I was.\",\n",
    "       'I think food should have flavor and texture and both were lacking.',\n",
    "       'Appetite instantly gone.',\n",
    "       'Overall I was not impressed and would not go back.',\n",
    "       \"The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.\",\n",
    "       \"Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check.\"]\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_yelp = df[df['company'] == 'yelp']\n",
    "sentences = df_yelp['sentence'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_yelp['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2748 entries, 0 to 747\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   sentence  2748 non-null   object\n 1   label     2748 non-null   int64 \n 2   company   2748 non-null   object\ndtypes: int64(1), object(2)\nmemory usage: 85.9+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "sentences, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<750x1714 sparse matrix of type '<class 'numpy.int64'>'\n\twith 7368 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test = vectorizer.transform(sentences_test)\n",
    "X_train\n",
    "'''\n",
    "<750x1714 sparse matrix of type '<class 'numpy.int64'>'\n",
    "\twith 7368 stored elements in Compressed Sparse Row format>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## A SIMPLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy:  0.796\n"
    }
   ],
   "source": [
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train) # fit the data to a logisticc regression\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    print(\"Accuracy: \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for yelp data: 0.7960\nAccuracy for amazon data: 0.7960\nAccuracy for imdb data: 0.7487\n"
    }
   ],
   "source": [
    "for company in df['company'].unique():\n",
    "    df_company = df[df['company'] == company]\n",
    "    sentences = df_company['sentence'].values # turn all into np array\n",
    "    y = df_company['label'].values # turn all into np array\n",
    "\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "        sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(sentences_train)\n",
    "    X_train = vectorizer.transform(sentences_train)\n",
    "    X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    print('Accuracy for {} data: {:.4f}'.format(company, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Primer on (Deep) Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitminiconda3virtualenv23608b0c183141fcba831b404dd00c83",
   "display_name": "Python 3.7.7 64-bit ('miniconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}